---
title: "Clustering and classification"
author: "Jaana Simola"
date: "11/21/2018"
output: html_document
---

# Week 4 - Clustering and classification

```{r}
rm(list = ls())  # clear workspace
library(MASS)
data("Boston")
str(Boston)
```

### Boston data set
This data has 506 osbervations (rows) and 14 variables (columns). The data includes information about housing values of  suburbs of Boston, such as crime rate, business, accessibility to highways, and characteristics of the citizens in the area. 

```{r, include=FALSE}
library(tidyr); library(dplyr); library(ggplot2); library(tidyverse); library(corrplot) # load libraries
```
### Plot the distibutions of the variables
```{r}
gather(Boston) %>% glimpse
gather(Boston) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_histogram() # bar plots
```

* 'age', 'black' and 'ptratio' are left skewed
* 'dis', 'Istat' and 'nox' are right skewed
*  most values of 'chas', 'crim' and 'zn' are zeros
* 'indus', 'rad' and 'tax' are bimodal
* 'medv' and 'rm' roughly normally distributed

### Summarize data
```{r}
summary(Boston)
```

### Correlations between the variables
```{r}
cor_matrix <-cor(Boston) 
cor_matrix <-round(cor_matrix, digits=2)
cor_matrix 
corrplot(cor_matrix, method = "color") 
```
  
Overall, the variables show strong correlations with each other, therefore only the strongest (> 0.7 or < -0.7) are interpreted below

* 'indus' correlates positively with 'nox' (0.76) and 'tax' (0.72) and negatively with 'dis' (-0.71), suggesting that the proportion of non-retail business acres is associated with higher nitrogen oxides concentration and tax rate and with  shorter distances from Boston employment centres.

* 'nox' correlates positively with 'age' (0.73) and negatively with 'dis' (-0.77), suggesting that the proportion of units  built prior to 1940 is associated with higher nitrogen oxides concentration and shorter distance from employment centres. 
* 'rm' correlates positively with 'medv' (0.7), suggesting that the average number of rooms is associated with higher median of owner-occupied homes in \$1000s.

* 'age' correlates negatively with 'dis' (-0.75), suggesting that the proportion of units  built prior to 1940 is associated with shorter distance from employment centres.

* 'rad' correlates with 'tax' (0.91): accessibility to highways is highly correlated with tax rate.

* 'lstat' correlates negatively with 'medv' (-0.74): the percentage of lower status population (is this appropriate??) is associated with lower amount of owner-occupied homes in \$1000s.

### Standardize the data
```{r}
boston_scaled <- scale(Boston)
summary(boston_scaled)
```
  
The data is now standardized to zero mean.

### Create a categorical variable of the crime rate 
```{r}
boston_scaled <- as.data.frame(boston_scaled)

bins <- quantile(boston_scaled$crim) # create a quantile vector of crim and print it

# create a categorical variable 'crime' 
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))
table(crime) # print the table
boston_scaled <- cbind(boston_scaled, crime) # bind crime to boston_scaled
boston_scaled <- dplyr::select(boston_scaled, -crim) # remove original crim from the dataset
```

###  Divide the dataset to train (80%) and test (20%) sets
```{r}
n <- nrow(boston_scaled) # number of rows
ind <- sample(n,  size = n * 0.8) # choose randomly 80% of the rows
train <- boston_scaled[ind,] # create the train set
test <- boston_scaled[-ind,] # create the test set 
```

### Fitting a linear discriminant analysis (LDA) to the dataset
```{r}
lda.fit <- lda(crime  ~., data = train) # crime rate is the target variable and all the other variables are predictors 
lda.fit # print the solution
classes <- as.numeric(train$crime) # target classes as numeric
plot(lda.fit, dimen = 2, col = classes, pch = classes) # plot the lda results
```

### Predict the classes with the LDA model on the test data
```{r}
correct_classes <- test$crime # save the crime categories from the test set 
test <- select(test, -crime) # remove crime from the test dataset
lda.pred <- predict(lda.fit, newdata = test) # predict classes with test data
table(correct = correct_classes, predicted = lda.pred$class) # Cross tabulate the results 
```
  
Overall, the model performs well in predicting the crime categories. The high crime category is predicted fully, medium high is predicted well execpt small confusion with medium low crime rate category. Low and med_low categories are mixed.  
### Reload and normalize Boston dataset and calculate the euclidean distances between the observations
```{r}
library(MASS)
data('Boston')
boston_scaled <- scale(Boston)
boston_scaled <- as.data.frame(boston_scaled)
dist_eu <- dist(boston_scaled) #Calculate the  distances
```


### Cluster the dataset with k-means function and plot the clusters. First, investigate what is the optimal number of clusters by looking at how the sum of squared distance changes with the number of clusters 
```{r}
k_max <- 25 # determine the maximum number of clusters
twcss <- sapply(1:k_max, function(k){kmeans(boston_scaled, k)$tot.withinss}) # calculate the total within sum of squares
qplot(x = 1:k_max, y = twcss, geom = 'line') # visualize the results

km <-kmeans(boston_scaled, centers = 5) # k-means clustering
pairs(boston_scaled, col = km$cluster) # plot the clusters
```
  
Five seems to be an optimal number of clusters, because a drop in the sum of squared distances around there.


```{r}
library(MASS)
data('Boston')
boston_scaled <- scale(Boston)
boston_scaled <- as.data.frame(boston_scaled)
# Perform k-means on the original Boston data with some reasonable number of clusters (> 2)
km_4 <-kmeans(boston_scaled, centers = 4) # k-means clustering
clusters <- as.numeric(km_4$cluster)
lda.fit4 <- lda(clusters  ~., data = boston_scaled) # perform LDA using the clusters  
lda.fit4

# the function to draw lda biplot arrows 
my_scale = 10 # unable to draw the arrows - i'm not sure what myscale does -tested with different values without any effect 
lda.arrows <- function(x, myscale = my_scale, arrow_heads = 0.1, color = "black", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

plot(lda.fit4, dimen = 3, col = clusters, pch = clusters)
lda.arrows(lda.fit4, myscale = my_scale)
```

